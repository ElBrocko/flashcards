###Question: show datatypes of each column in df

Answer: df.dtypes

Note:

###Question: # split into training and testing sets
# build a linear regression model on 
X and y defined as
X = crime.drop(127, axis=1)
y = crime[127]

# split into training and testing sets

Answer: from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)
linreg = LinearRegression()
linreg.fit(X_train, y_train)

Note:

###Question: 
# define X and y
X = crime.drop(127, axis=1)
y = crime[127]

# split into training and testing sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)

# build a linear regression model
from sklearn.linear_model import LinearRegression
linreg = LinearRegression()
linreg.fit(X_train, y_train)

****# examine the coefficients
****# make predictions

Answer: print(linreg.coef_)
y_pred = linreg.predict(X_test)

Note:

###Question: # calculate RMSE

Answer: from sklearn import metrics
import numpy as np
print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

Note:

###Question:  # ridge regression

# alpha=0 is equivalent to linear regression

# try alpha=0.1

# examine the coefficients

Answer: from sklearn.linear_model import Ridge
ridgereg = Ridge(alpha=0, normalize=True)
ridgereg.fit(X_train, y_train)
y_pred = ridgereg.predict(X_test)
print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

ridgereg = Ridge(alpha=0.1, normalize=True)
ridgereg.fit(X_train, y_train)
y_pred = ridgereg.predict(X_test)
print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))
print(ridgereg.coef_)

Note:

###Question: # create an array of alpha values

Answer: alpha_range = 10.**np.arange(-2, 3)
alpha_range 

Note:

###Question: # select the best alpha with RidgeCV


# predict method uses the best alpha value


Answer:
from sklearn.linear_model import RidgeCV
ridgeregcv = RidgeCV(alphas=alpha_range, normalize=True, scoring='mean_squared_error')
ridgeregcv.fit(X_train, y_train)
ridgeregcv.alpha_
y_pred = ridgeregcv.predict(X_test)
print np.sqrt(metrics.mean_squared_error(y_test, y_pred))
Note:

###Question: # visualize the relationship between the features and the response using scatterplots ('TV','Radio','Newspaper' are features to predict 'Sales')

Answer: sns.pairplot(data, x_vars=['TV','Radio','Newspaper'], y_vars='Sales', size=7, aspect=0.7, kind='reg')
Note:

###Question:
# create a Python list of feature names (TV, Radio, Newspaper)

# use the list to select a subset of the original DataFrame
# equivalent command to do this in one line
# print the first 5 rows
# check the type and shape of X
# select the Sales Series from the DataFrame
# create train / test sets
# show that default split is 75% for training and 25% for testing
# import linreg model
# instantiate
# fit the model to the training data (learn the coefficients)
# print the intercept and coefficients
# pair the feature names with the coefficients
# make predictions on the testing set

Answer:
X = data[feature_cols]
feature_cols = ['TV', 'Radio', 'Newspaper']
X = data[['TV', 'Radio', 'Newspaper']]
X.head()
print(type(X))
print(X.shape)
y = data['Sales']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1) 
print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)
from sklearn.linear_model import LinearRegression
linreg = LinearRegression()
linreg.fit(X_train, y_train)
print(linreg.intercept_)
print(linreg.coef_)
list(zip(feature_cols, linreg.coef_))
y_pred = linreg.predict(X_test)

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

###Question: 

Answer:

Note:

